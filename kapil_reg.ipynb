{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def generate_dataset():\n",
    " x_batch = np.linspace(0, 2, 100)\n",
    " y_batch = 1.5 * x_batch + np.random.randn(*x_batch.shape) * 0.2 + 0.5\n",
    " return x_batch, y_batch\n",
    "\n",
    "def linear_regression():\n",
    "  x = tf.placeholder(tf.float32, shape=(None, ), name='x')\n",
    "  y = tf.placeholder(tf.float32, shape=(None, ), name='y')\n",
    "\n",
    "  with tf.variable_scope('lreg') as scope:\n",
    "    w = tf.Variable(np.random.normal(), name='W')\n",
    "    b = tf.Variable(np.random.normal(), name='b')\n",
    "\t\t\n",
    "    y_pred = tf.add(tf.multiply(w, x), b)\n",
    "\n",
    "    loss = tf.reduce_mean(tf.square(y_pred - y))\n",
    "\n",
    "  return x, y, y_pred, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss: 0.30520844\n",
      "1 loss: 0.14161506\n",
      "2 loss: 0.08913685\n",
      "3 loss: 0.07193089\n",
      "4 loss: 0.06594465\n",
      "5 loss: 0.06354875\n",
      "6 loss: 0.062321883\n",
      "7 loss: 0.06149436\n",
      "8 loss: 0.060820345\n",
      "9 loss: 0.060220245\n",
      "10 loss: 0.05966728\n",
      "11 loss: 0.059151486\n",
      "12 loss: 0.05866834\n",
      "13 loss: 0.058215164\n",
      "14 loss: 0.05778986\n",
      "15 loss: 0.057390653\n",
      "16 loss: 0.057015944\n",
      "17 loss: 0.0566642\n",
      "18 loss: 0.056334034\n",
      "19 loss: 0.056024093\n",
      "20 loss: 0.055733155\n",
      "21 loss: 0.055460066\n",
      "22 loss: 0.05520369\n",
      "23 loss: 0.054963056\n",
      "24 loss: 0.054737158\n",
      "25 loss: 0.05452512\n",
      "26 loss: 0.054326072\n",
      "27 loss: 0.054139227\n",
      "28 loss: 0.053963847\n",
      "29 loss: 0.0537992\n",
      "30 loss: 0.05364466\n",
      "31 loss: 0.053499594\n",
      "32 loss: 0.053363405\n",
      "33 loss: 0.053235576\n",
      "34 loss: 0.05311559\n",
      "35 loss: 0.053002954\n",
      "36 loss: 0.052897226\n",
      "37 loss: 0.052797977\n",
      "38 loss: 0.052704815\n",
      "39 loss: 0.052617364\n",
      "40 loss: 0.052535273\n",
      "41 loss: 0.05245821\n",
      "42 loss: 0.05238587\n",
      "43 loss: 0.052317966\n",
      "44 loss: 0.052254222\n",
      "45 loss: 0.052194394\n",
      "46 loss: 0.052138224\n",
      "47 loss: 0.052085508\n",
      "48 loss: 0.052036017\n",
      "49 loss: 0.05198956\n",
      "50 loss: 0.051945955\n",
      "51 loss: 0.05190502\n",
      "52 loss: 0.051866587\n",
      "53 loss: 0.05183053\n",
      "54 loss: 0.05179667\n",
      "55 loss: 0.051764894\n",
      "56 loss: 0.051735055\n",
      "57 loss: 0.051707044\n",
      "58 loss: 0.051680755\n",
      "59 loss: 0.051656093\n",
      "60 loss: 0.05163293\n",
      "61 loss: 0.051611174\n",
      "62 loss: 0.051590767\n",
      "63 loss: 0.051571608\n",
      "64 loss: 0.051553626\n",
      "65 loss: 0.051536735\n",
      "66 loss: 0.05152089\n",
      "67 loss: 0.051506013\n",
      "68 loss: 0.051492043\n",
      "69 loss: 0.051478934\n",
      "70 loss: 0.05146663\n",
      "71 loss: 0.051455084\n",
      "72 loss: 0.051444244\n",
      "73 loss: 0.05143407\n",
      "74 loss: 0.051424522\n",
      "75 loss: 0.051415544\n",
      "76 loss: 0.051407132\n",
      "77 loss: 0.05139922\n",
      "78 loss: 0.051391795\n",
      "79 loss: 0.05138485\n",
      "80 loss: 0.051378306\n",
      "81 loss: 0.05137217\n",
      "82 loss: 0.05136641\n",
      "83 loss: 0.05136101\n",
      "84 loss: 0.051355936\n",
      "85 loss: 0.051351167\n",
      "86 loss: 0.05134669\n",
      "87 loss: 0.051342502\n",
      "88 loss: 0.051338557\n",
      "89 loss: 0.051334854\n",
      "90 loss: 0.051331386\n",
      "91 loss: 0.051328126\n",
      "92 loss: 0.05132507\n",
      "93 loss: 0.051322192\n",
      "94 loss: 0.0513195\n",
      "95 loss: 0.051316965\n",
      "96 loss: 0.051314604\n",
      "97 loss: 0.05131236\n",
      "98 loss: 0.05131027\n",
      "99 loss: 0.05130832\n",
      "100 loss: 0.051306464\n",
      "101 loss: 0.05130473\n",
      "102 loss: 0.05130311\n",
      "103 loss: 0.051301584\n",
      "104 loss: 0.051300153\n",
      "105 loss: 0.051298805\n",
      "106 loss: 0.051297545\n",
      "107 loss: 0.051296357\n",
      "108 loss: 0.051295247\n",
      "109 loss: 0.051294208\n",
      "110 loss: 0.05129322\n",
      "111 loss: 0.051292296\n",
      "112 loss: 0.051291443\n",
      "113 loss: 0.051290628\n",
      "114 loss: 0.05128987\n",
      "115 loss: 0.051289152\n",
      "116 loss: 0.051288486\n",
      "117 loss: 0.051287852\n",
      "118 loss: 0.051287264\n",
      "119 loss: 0.051286712\n",
      "120 loss: 0.051286187\n",
      "121 loss: 0.051285706\n",
      "122 loss: 0.05128525\n",
      "123 loss: 0.051284824\n",
      "124 loss: 0.051284418\n",
      "125 loss: 0.051284038\n",
      "126 loss: 0.051283672\n",
      "127 loss: 0.05128334\n",
      "128 loss: 0.051283024\n",
      "129 loss: 0.05128273\n",
      "130 loss: 0.051282443\n",
      "131 loss: 0.051282197\n",
      "132 loss: 0.05128196\n",
      "133 loss: 0.051281728\n",
      "134 loss: 0.051281508\n",
      "135 loss: 0.051281303\n",
      "136 loss: 0.051281117\n",
      "137 loss: 0.051280946\n",
      "138 loss: 0.051280774\n",
      "139 loss: 0.051280618\n",
      "140 loss: 0.051280476\n",
      "141 loss: 0.051280335\n",
      "142 loss: 0.051280204\n",
      "143 loss: 0.051280085\n",
      "144 loss: 0.05127997\n",
      "145 loss: 0.051279865\n",
      "146 loss: 0.051279765\n",
      "147 loss: 0.051279664\n",
      "148 loss: 0.051279582\n",
      "149 loss: 0.051279496\n",
      "150 loss: 0.05127941\n",
      "151 loss: 0.051279344\n",
      "152 loss: 0.051279277\n",
      "153 loss: 0.05127921\n",
      "154 loss: 0.05127915\n",
      "155 loss: 0.051279087\n",
      "156 loss: 0.05127904\n",
      "157 loss: 0.051278997\n",
      "158 loss: 0.051278945\n",
      "159 loss: 0.0512789\n",
      "160 loss: 0.05127886\n",
      "161 loss: 0.051278815\n",
      "162 loss: 0.05127878\n",
      "163 loss: 0.051278744\n",
      "164 loss: 0.05127871\n",
      "165 loss: 0.05127869\n",
      "166 loss: 0.051278654\n",
      "167 loss: 0.05127864\n",
      "168 loss: 0.051278606\n",
      "169 loss: 0.05127858\n",
      "170 loss: 0.051278558\n",
      "171 loss: 0.05127854\n",
      "172 loss: 0.051278524\n",
      "173 loss: 0.051278494\n",
      "174 loss: 0.051278483\n",
      "175 loss: 0.05127847\n",
      "176 loss: 0.051278457\n",
      "177 loss: 0.051278435\n",
      "178 loss: 0.051278435\n",
      "179 loss: 0.051278416\n",
      "180 loss: 0.0512784\n",
      "181 loss: 0.051278397\n",
      "182 loss: 0.051278383\n",
      "183 loss: 0.05127837\n",
      "184 loss: 0.051278364\n",
      "185 loss: 0.051278353\n",
      "186 loss: 0.051278338\n",
      "187 loss: 0.051278338\n",
      "188 loss: 0.051278323\n",
      "189 loss: 0.051278323\n",
      "190 loss: 0.051278315\n",
      "191 loss: 0.051278308\n",
      "192 loss: 0.051278304\n",
      "193 loss: 0.05127829\n",
      "194 loss: 0.0512783\n",
      "195 loss: 0.05127829\n",
      "196 loss: 0.05127829\n",
      "197 loss: 0.051278286\n",
      "198 loss: 0.051278286\n",
      "199 loss: 0.05127827\n",
      "200 loss: 0.05127828\n",
      "201 loss: 0.051278267\n",
      "202 loss: 0.051278267\n",
      "203 loss: 0.051278263\n",
      "204 loss: 0.051278267\n",
      "205 loss: 0.051278263\n",
      "206 loss: 0.051278256\n",
      "207 loss: 0.05127825\n",
      "208 loss: 0.051278252\n",
      "209 loss: 0.05127825\n",
      "210 loss: 0.05127825\n",
      "211 loss: 0.05127825\n",
      "212 loss: 0.05127825\n",
      "213 loss: 0.051278245\n",
      "214 loss: 0.051278237\n",
      "215 loss: 0.051278234\n",
      "216 loss: 0.051278245\n",
      "217 loss: 0.051278237\n",
      "218 loss: 0.051278237\n",
      "219 loss: 0.051278237\n",
      "220 loss: 0.051278234\n",
      "221 loss: 0.051278237\n",
      "222 loss: 0.05127823\n",
      "223 loss: 0.051278237\n",
      "224 loss: 0.051278234\n",
      "225 loss: 0.051278237\n",
      "226 loss: 0.05127823\n",
      "227 loss: 0.051278234\n",
      "228 loss: 0.05127823\n",
      "229 loss: 0.051278234\n",
      "230 loss: 0.05127823\n",
      "231 loss: 0.05127823\n",
      "232 loss: 0.051278234\n",
      "233 loss: 0.05127823\n",
      "234 loss: 0.05127823\n",
      "235 loss: 0.05127823\n",
      "236 loss: 0.051278222\n",
      "237 loss: 0.05127823\n",
      "238 loss: 0.051278222\n",
      "239 loss: 0.051278222\n",
      "240 loss: 0.05127823\n",
      "241 loss: 0.051278222\n",
      "242 loss: 0.05127823\n",
      "243 loss: 0.05127822\n",
      "244 loss: 0.051278222\n",
      "245 loss: 0.05127823\n",
      "246 loss: 0.05127822\n",
      "247 loss: 0.05127823\n",
      "248 loss: 0.05127823\n",
      "249 loss: 0.051278222\n",
      "250 loss: 0.05127822\n",
      "251 loss: 0.051278222\n",
      "252 loss: 0.05127823\n",
      "253 loss: 0.051278222\n",
      "254 loss: 0.05127823\n",
      "255 loss: 0.051278222\n",
      "256 loss: 0.051278222\n",
      "257 loss: 0.05127822\n",
      "258 loss: 0.051278222\n",
      "259 loss: 0.05127822\n",
      "260 loss: 0.05127822\n",
      "261 loss: 0.051278222\n",
      "262 loss: 0.051278222\n",
      "263 loss: 0.05127823\n",
      "264 loss: 0.051278215\n",
      "265 loss: 0.05127822\n",
      "266 loss: 0.051278222\n",
      "267 loss: 0.05127822\n",
      "268 loss: 0.05127822\n",
      "269 loss: 0.05127822\n",
      "270 loss: 0.05127822\n",
      "271 loss: 0.051278222\n",
      "272 loss: 0.051278222\n",
      "273 loss: 0.05127822\n",
      "274 loss: 0.05127822\n",
      "275 loss: 0.051278222\n",
      "276 loss: 0.05127822\n",
      "277 loss: 0.05127822\n",
      "278 loss: 0.051278222\n",
      "279 loss: 0.051278222\n",
      "280 loss: 0.05127822\n",
      "281 loss: 0.05127822\n",
      "282 loss: 0.051278222\n",
      "283 loss: 0.05127822\n",
      "284 loss: 0.05127822\n",
      "285 loss: 0.05127823\n",
      "286 loss: 0.051278222\n",
      "287 loss: 0.051278222\n",
      "288 loss: 0.051278222\n",
      "289 loss: 0.051278222\n",
      "290 loss: 0.05127822\n",
      "291 loss: 0.05127822\n",
      "292 loss: 0.05127822\n",
      "293 loss: 0.05127822\n",
      "294 loss: 0.051278222\n",
      "295 loss: 0.051278222\n",
      "296 loss: 0.05127822\n",
      "297 loss: 0.051278222\n",
      "298 loss: 0.05127822\n",
      "299 loss: 0.05127822\n",
      "300 loss: 0.051278222\n",
      "301 loss: 0.051278222\n",
      "302 loss: 0.051278222\n",
      "303 loss: 0.051278222\n",
      "304 loss: 0.051278215\n",
      "305 loss: 0.051278222\n",
      "306 loss: 0.05127822\n",
      "307 loss: 0.05127822\n",
      "308 loss: 0.05127823\n",
      "309 loss: 0.05127822\n",
      "310 loss: 0.05127822\n",
      "311 loss: 0.05127823\n",
      "312 loss: 0.051278222\n",
      "313 loss: 0.051278222\n",
      "314 loss: 0.05127822\n",
      "315 loss: 0.05127822\n",
      "316 loss: 0.05127822\n",
      "317 loss: 0.05127822\n",
      "318 loss: 0.051278222\n",
      "319 loss: 0.051278215\n",
      "320 loss: 0.051278215\n",
      "321 loss: 0.051278222\n",
      "322 loss: 0.051278222\n",
      "323 loss: 0.051278222\n",
      "324 loss: 0.051278222\n",
      "325 loss: 0.051278222\n",
      "326 loss: 0.051278222\n",
      "327 loss: 0.051278222\n",
      "328 loss: 0.051278222\n",
      "329 loss: 0.05127822\n",
      "330 loss: 0.051278222\n",
      "331 loss: 0.05127822\n",
      "332 loss: 0.05127822\n",
      "333 loss: 0.05127822\n",
      "334 loss: 0.05127822\n",
      "335 loss: 0.051278222\n",
      "336 loss: 0.051278222\n",
      "337 loss: 0.05127822\n",
      "338 loss: 0.051278222\n",
      "339 loss: 0.05127822\n",
      "340 loss: 0.05127822\n",
      "341 loss: 0.05127822\n",
      "342 loss: 0.05127822\n",
      "343 loss: 0.05127822\n",
      "344 loss: 0.05127822\n",
      "345 loss: 0.05127823\n",
      "346 loss: 0.05127823\n",
      "347 loss: 0.05127822\n",
      "348 loss: 0.05127822\n",
      "349 loss: 0.051278222\n",
      "350 loss: 0.05127822\n",
      "351 loss: 0.05127823\n",
      "352 loss: 0.05127822\n",
      "353 loss: 0.05127822\n",
      "354 loss: 0.051278222\n",
      "355 loss: 0.05127823\n",
      "356 loss: 0.051278222\n",
      "357 loss: 0.05127823\n",
      "358 loss: 0.051278222\n",
      "359 loss: 0.051278234\n",
      "360 loss: 0.05127823\n",
      "361 loss: 0.05127823\n",
      "362 loss: 0.05127822\n",
      "363 loss: 0.051278222\n",
      "364 loss: 0.051278222\n",
      "365 loss: 0.05127823\n",
      "366 loss: 0.051278222\n",
      "367 loss: 0.051278215\n",
      "368 loss: 0.05127822\n",
      "369 loss: 0.05127822\n",
      "370 loss: 0.051278215\n",
      "371 loss: 0.05127822\n",
      "372 loss: 0.051278215\n",
      "373 loss: 0.051278222\n",
      "374 loss: 0.051278215\n",
      "375 loss: 0.051278222\n",
      "376 loss: 0.051278222\n",
      "377 loss: 0.05127822\n",
      "378 loss: 0.051278222\n",
      "379 loss: 0.051278222\n",
      "380 loss: 0.051278222\n",
      "381 loss: 0.05127823\n",
      "382 loss: 0.051278222\n",
      "383 loss: 0.051278222\n",
      "384 loss: 0.051278215\n",
      "385 loss: 0.051278222\n",
      "386 loss: 0.051278215\n",
      "387 loss: 0.051278215\n",
      "388 loss: 0.051278222\n",
      "389 loss: 0.05127822\n",
      "390 loss: 0.051278215\n",
      "391 loss: 0.05127822\n",
      "392 loss: 0.051278215\n",
      "393 loss: 0.051278215\n",
      "394 loss: 0.051278222\n",
      "395 loss: 0.05127822\n",
      "396 loss: 0.051278215\n",
      "397 loss: 0.05127822\n",
      "398 loss: 0.05127822\n",
      "399 loss: 0.05127822\n",
      "400 loss: 0.05127822\n",
      "401 loss: 0.05127822\n",
      "402 loss: 0.05127822\n",
      "403 loss: 0.05127822\n",
      "404 loss: 0.05127822\n",
      "405 loss: 0.05127822\n",
      "406 loss: 0.05127822\n",
      "407 loss: 0.05127822\n",
      "408 loss: 0.05127822\n",
      "409 loss: 0.05127822\n",
      "410 loss: 0.05127822\n",
      "411 loss: 0.05127822\n",
      "412 loss: 0.05127822\n",
      "413 loss: 0.05127822\n",
      "414 loss: 0.05127822\n",
      "415 loss: 0.05127822\n",
      "416 loss: 0.05127822\n",
      "417 loss: 0.05127822\n",
      "418 loss: 0.05127822\n",
      "419 loss: 0.05127822\n",
      "420 loss: 0.05127822\n",
      "421 loss: 0.05127822\n",
      "422 loss: 0.05127822\n",
      "423 loss: 0.05127822\n",
      "424 loss: 0.05127822\n",
      "425 loss: 0.05127822\n",
      "426 loss: 0.05127822\n",
      "427 loss: 0.05127822\n",
      "428 loss: 0.05127822\n",
      "429 loss: 0.05127822\n",
      "430 loss: 0.05127822\n",
      "431 loss: 0.05127822\n",
      "432 loss: 0.05127822\n",
      "433 loss: 0.05127822\n",
      "434 loss: 0.05127822\n",
      "435 loss: 0.05127822\n",
      "436 loss: 0.05127822\n",
      "437 loss: 0.05127822\n",
      "438 loss: 0.05127822\n",
      "439 loss: 0.05127822\n",
      "440 loss: 0.05127822\n",
      "441 loss: 0.05127822\n",
      "442 loss: 0.05127822\n",
      "443 loss: 0.05127822\n",
      "444 loss: 0.05127822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "445 loss: 0.05127822\n",
      "446 loss: 0.05127822\n",
      "447 loss: 0.05127822\n",
      "448 loss: 0.05127822\n",
      "449 loss: 0.05127822\n",
      "450 loss: 0.05127822\n",
      "451 loss: 0.05127822\n",
      "452 loss: 0.05127822\n",
      "453 loss: 0.05127822\n",
      "454 loss: 0.05127822\n",
      "455 loss: 0.05127822\n",
      "456 loss: 0.05127822\n",
      "457 loss: 0.05127822\n",
      "458 loss: 0.05127822\n",
      "459 loss: 0.05127822\n",
      "460 loss: 0.05127822\n",
      "461 loss: 0.05127822\n",
      "462 loss: 0.05127822\n",
      "463 loss: 0.05127822\n",
      "464 loss: 0.05127822\n",
      "465 loss: 0.05127822\n",
      "466 loss: 0.05127822\n",
      "467 loss: 0.05127822\n",
      "468 loss: 0.05127822\n",
      "469 loss: 0.05127822\n",
      "470 loss: 0.05127822\n",
      "471 loss: 0.05127822\n",
      "472 loss: 0.05127822\n",
      "473 loss: 0.05127822\n",
      "474 loss: 0.05127822\n",
      "475 loss: 0.05127822\n",
      "476 loss: 0.05127822\n",
      "477 loss: 0.05127822\n",
      "478 loss: 0.05127822\n",
      "479 loss: 0.05127822\n",
      "480 loss: 0.05127822\n",
      "481 loss: 0.05127822\n",
      "482 loss: 0.05127822\n",
      "483 loss: 0.05127822\n",
      "484 loss: 0.05127822\n",
      "485 loss: 0.05127822\n",
      "486 loss: 0.05127822\n",
      "487 loss: 0.05127822\n",
      "488 loss: 0.05127822\n",
      "489 loss: 0.05127822\n",
      "490 loss: 0.05127822\n",
      "491 loss: 0.05127822\n",
      "492 loss: 0.05127822\n",
      "493 loss: 0.05127822\n",
      "494 loss: 0.05127822\n",
      "495 loss: 0.05127822\n",
      "496 loss: 0.05127822\n",
      "497 loss: 0.05127822\n",
      "498 loss: 0.05127822\n",
      "499 loss: 0.05127822\n",
      "500 loss: 0.05127822\n",
      "501 loss: 0.05127822\n",
      "502 loss: 0.05127822\n",
      "503 loss: 0.05127822\n",
      "504 loss: 0.05127822\n",
      "505 loss: 0.05127822\n",
      "506 loss: 0.05127822\n",
      "507 loss: 0.05127822\n",
      "508 loss: 0.05127822\n",
      "509 loss: 0.05127822\n",
      "510 loss: 0.05127822\n",
      "511 loss: 0.05127822\n",
      "512 loss: 0.05127822\n",
      "513 loss: 0.05127822\n",
      "514 loss: 0.05127822\n",
      "515 loss: 0.05127822\n",
      "516 loss: 0.05127822\n",
      "517 loss: 0.05127822\n",
      "518 loss: 0.05127822\n",
      "519 loss: 0.05127822\n",
      "520 loss: 0.05127822\n",
      "521 loss: 0.05127822\n",
      "522 loss: 0.05127822\n",
      "523 loss: 0.05127822\n",
      "524 loss: 0.05127822\n",
      "525 loss: 0.05127822\n",
      "526 loss: 0.05127822\n",
      "527 loss: 0.05127822\n",
      "528 loss: 0.05127822\n",
      "529 loss: 0.05127822\n",
      "530 loss: 0.05127822\n",
      "531 loss: 0.05127822\n",
      "532 loss: 0.05127822\n",
      "533 loss: 0.05127822\n",
      "534 loss: 0.05127822\n",
      "535 loss: 0.05127822\n",
      "536 loss: 0.05127822\n",
      "537 loss: 0.05127822\n",
      "538 loss: 0.05127822\n",
      "539 loss: 0.05127822\n",
      "540 loss: 0.05127822\n",
      "541 loss: 0.05127822\n",
      "542 loss: 0.05127822\n",
      "543 loss: 0.05127822\n",
      "544 loss: 0.05127822\n",
      "545 loss: 0.05127822\n",
      "546 loss: 0.05127822\n",
      "547 loss: 0.05127822\n",
      "548 loss: 0.05127822\n",
      "549 loss: 0.05127822\n",
      "550 loss: 0.05127822\n",
      "551 loss: 0.05127822\n",
      "552 loss: 0.05127822\n",
      "553 loss: 0.05127822\n",
      "554 loss: 0.05127822\n",
      "555 loss: 0.05127822\n",
      "556 loss: 0.05127822\n",
      "557 loss: 0.05127822\n",
      "558 loss: 0.05127822\n",
      "559 loss: 0.05127822\n",
      "560 loss: 0.05127822\n",
      "561 loss: 0.05127822\n",
      "562 loss: 0.05127822\n",
      "563 loss: 0.05127822\n",
      "564 loss: 0.05127822\n",
      "565 loss: 0.05127822\n",
      "566 loss: 0.05127822\n",
      "567 loss: 0.05127822\n",
      "568 loss: 0.05127822\n",
      "569 loss: 0.05127822\n",
      "570 loss: 0.05127822\n",
      "571 loss: 0.05127822\n",
      "572 loss: 0.05127822\n",
      "573 loss: 0.05127822\n",
      "574 loss: 0.05127822\n",
      "575 loss: 0.05127822\n",
      "576 loss: 0.05127822\n",
      "577 loss: 0.05127822\n",
      "578 loss: 0.05127822\n",
      "579 loss: 0.05127822\n",
      "580 loss: 0.05127822\n",
      "581 loss: 0.05127822\n",
      "582 loss: 0.05127822\n",
      "583 loss: 0.05127822\n",
      "584 loss: 0.05127822\n",
      "585 loss: 0.05127822\n",
      "586 loss: 0.05127822\n",
      "587 loss: 0.05127822\n",
      "588 loss: 0.05127822\n",
      "589 loss: 0.05127822\n",
      "590 loss: 0.05127822\n",
      "591 loss: 0.05127822\n",
      "592 loss: 0.05127822\n",
      "593 loss: 0.05127822\n",
      "594 loss: 0.05127822\n",
      "595 loss: 0.05127822\n",
      "596 loss: 0.05127822\n",
      "597 loss: 0.05127822\n",
      "598 loss: 0.05127822\n",
      "599 loss: 0.05127822\n",
      "600 loss: 0.05127822\n",
      "601 loss: 0.05127822\n",
      "602 loss: 0.05127822\n",
      "603 loss: 0.05127822\n",
      "604 loss: 0.05127822\n",
      "605 loss: 0.05127822\n",
      "606 loss: 0.05127822\n",
      "607 loss: 0.05127822\n",
      "608 loss: 0.05127822\n",
      "609 loss: 0.05127822\n",
      "610 loss: 0.05127822\n",
      "611 loss: 0.05127822\n",
      "612 loss: 0.05127822\n",
      "613 loss: 0.05127822\n",
      "614 loss: 0.05127822\n",
      "615 loss: 0.05127822\n",
      "616 loss: 0.05127822\n",
      "617 loss: 0.05127822\n",
      "618 loss: 0.05127822\n",
      "619 loss: 0.05127822\n",
      "620 loss: 0.05127822\n",
      "621 loss: 0.05127822\n",
      "622 loss: 0.05127822\n",
      "623 loss: 0.05127822\n",
      "624 loss: 0.05127822\n",
      "625 loss: 0.05127822\n",
      "626 loss: 0.05127822\n",
      "627 loss: 0.05127822\n",
      "628 loss: 0.05127822\n",
      "629 loss: 0.05127822\n",
      "630 loss: 0.05127822\n",
      "631 loss: 0.05127822\n",
      "632 loss: 0.05127822\n",
      "633 loss: 0.05127822\n",
      "634 loss: 0.05127822\n",
      "635 loss: 0.05127822\n",
      "636 loss: 0.05127822\n",
      "637 loss: 0.05127822\n",
      "638 loss: 0.05127822\n",
      "639 loss: 0.05127822\n",
      "640 loss: 0.05127822\n",
      "641 loss: 0.05127822\n",
      "642 loss: 0.05127822\n",
      "643 loss: 0.05127822\n",
      "644 loss: 0.05127822\n",
      "645 loss: 0.05127822\n",
      "646 loss: 0.05127822\n",
      "647 loss: 0.05127822\n",
      "648 loss: 0.05127822\n",
      "649 loss: 0.05127822\n",
      "650 loss: 0.05127822\n",
      "651 loss: 0.05127822\n",
      "652 loss: 0.05127822\n",
      "653 loss: 0.05127822\n",
      "654 loss: 0.05127822\n",
      "655 loss: 0.05127822\n",
      "656 loss: 0.05127822\n",
      "657 loss: 0.05127822\n",
      "658 loss: 0.05127822\n",
      "659 loss: 0.05127822\n",
      "660 loss: 0.05127822\n",
      "661 loss: 0.05127822\n",
      "662 loss: 0.05127822\n",
      "663 loss: 0.05127822\n",
      "664 loss: 0.05127822\n",
      "665 loss: 0.05127822\n",
      "666 loss: 0.05127822\n",
      "667 loss: 0.05127822\n",
      "668 loss: 0.05127822\n",
      "669 loss: 0.05127822\n",
      "670 loss: 0.05127822\n",
      "671 loss: 0.05127822\n",
      "672 loss: 0.05127822\n",
      "673 loss: 0.05127822\n",
      "674 loss: 0.05127822\n",
      "675 loss: 0.05127822\n",
      "676 loss: 0.05127822\n",
      "677 loss: 0.05127822\n",
      "678 loss: 0.05127822\n",
      "679 loss: 0.05127822\n",
      "680 loss: 0.05127822\n",
      "681 loss: 0.05127822\n",
      "682 loss: 0.05127822\n",
      "683 loss: 0.05127822\n",
      "684 loss: 0.05127822\n",
      "685 loss: 0.05127822\n",
      "686 loss: 0.05127822\n",
      "687 loss: 0.05127822\n",
      "688 loss: 0.05127822\n",
      "689 loss: 0.05127822\n",
      "690 loss: 0.05127822\n",
      "691 loss: 0.05127822\n",
      "692 loss: 0.05127822\n",
      "693 loss: 0.05127822\n",
      "694 loss: 0.05127822\n",
      "695 loss: 0.05127822\n",
      "696 loss: 0.05127822\n",
      "697 loss: 0.05127822\n",
      "698 loss: 0.05127822\n",
      "699 loss: 0.05127822\n",
      "700 loss: 0.05127822\n",
      "701 loss: 0.05127822\n",
      "702 loss: 0.05127822\n",
      "703 loss: 0.05127822\n",
      "704 loss: 0.05127822\n",
      "705 loss: 0.05127822\n",
      "706 loss: 0.05127822\n",
      "707 loss: 0.05127822\n",
      "708 loss: 0.05127822\n",
      "709 loss: 0.05127822\n",
      "710 loss: 0.05127822\n",
      "711 loss: 0.05127822\n",
      "712 loss: 0.05127822\n",
      "713 loss: 0.05127822\n",
      "714 loss: 0.05127822\n",
      "715 loss: 0.05127822\n",
      "716 loss: 0.05127822\n",
      "717 loss: 0.05127822\n",
      "718 loss: 0.05127822\n",
      "719 loss: 0.05127822\n",
      "720 loss: 0.05127822\n",
      "721 loss: 0.05127822\n",
      "722 loss: 0.05127822\n",
      "723 loss: 0.05127822\n",
      "724 loss: 0.05127822\n",
      "725 loss: 0.05127822\n",
      "726 loss: 0.05127822\n",
      "727 loss: 0.05127822\n",
      "728 loss: 0.05127822\n",
      "729 loss: 0.05127822\n",
      "730 loss: 0.05127822\n",
      "731 loss: 0.05127822\n",
      "732 loss: 0.05127822\n",
      "733 loss: 0.05127822\n",
      "734 loss: 0.05127822\n",
      "735 loss: 0.05127822\n",
      "736 loss: 0.05127822\n",
      "737 loss: 0.05127822\n",
      "738 loss: 0.05127822\n",
      "739 loss: 0.05127822\n",
      "740 loss: 0.05127822\n",
      "741 loss: 0.05127822\n",
      "742 loss: 0.05127822\n",
      "743 loss: 0.05127822\n",
      "744 loss: 0.05127822\n",
      "745 loss: 0.05127822\n",
      "746 loss: 0.05127822\n",
      "747 loss: 0.05127822\n",
      "748 loss: 0.05127822\n",
      "749 loss: 0.05127822\n",
      "750 loss: 0.05127822\n",
      "751 loss: 0.05127822\n",
      "752 loss: 0.05127822\n",
      "753 loss: 0.05127822\n",
      "754 loss: 0.05127822\n",
      "755 loss: 0.05127822\n",
      "756 loss: 0.05127822\n",
      "757 loss: 0.05127822\n",
      "758 loss: 0.05127822\n",
      "759 loss: 0.05127822\n",
      "760 loss: 0.05127822\n",
      "761 loss: 0.05127822\n",
      "762 loss: 0.05127822\n",
      "763 loss: 0.05127822\n",
      "764 loss: 0.05127822\n",
      "765 loss: 0.05127822\n",
      "766 loss: 0.05127822\n",
      "767 loss: 0.05127822\n",
      "768 loss: 0.05127822\n",
      "769 loss: 0.05127822\n",
      "770 loss: 0.05127822\n",
      "771 loss: 0.05127822\n",
      "772 loss: 0.05127822\n",
      "773 loss: 0.05127822\n",
      "774 loss: 0.05127822\n",
      "775 loss: 0.05127822\n",
      "776 loss: 0.05127822\n",
      "777 loss: 0.05127822\n",
      "778 loss: 0.05127822\n",
      "779 loss: 0.05127822\n",
      "780 loss: 0.05127822\n",
      "781 loss: 0.05127822\n",
      "782 loss: 0.05127822\n",
      "783 loss: 0.05127822\n",
      "784 loss: 0.05127822\n",
      "785 loss: 0.05127822\n",
      "786 loss: 0.05127822\n",
      "787 loss: 0.05127822\n",
      "788 loss: 0.05127822\n",
      "789 loss: 0.05127822\n",
      "790 loss: 0.05127822\n",
      "791 loss: 0.05127822\n",
      "792 loss: 0.05127822\n",
      "793 loss: 0.05127822\n",
      "794 loss: 0.05127822\n",
      "795 loss: 0.05127822\n",
      "796 loss: 0.05127822\n",
      "797 loss: 0.05127822\n",
      "798 loss: 0.05127822\n",
      "799 loss: 0.05127822\n",
      "800 loss: 0.05127822\n",
      "801 loss: 0.05127822\n",
      "802 loss: 0.05127822\n",
      "803 loss: 0.05127822\n",
      "804 loss: 0.05127822\n",
      "805 loss: 0.05127822\n",
      "806 loss: 0.05127822\n",
      "807 loss: 0.05127822\n",
      "808 loss: 0.05127822\n",
      "809 loss: 0.05127822\n",
      "810 loss: 0.05127822\n",
      "811 loss: 0.05127822\n",
      "812 loss: 0.05127822\n",
      "813 loss: 0.05127822\n",
      "814 loss: 0.05127822\n",
      "815 loss: 0.05127822\n",
      "816 loss: 0.05127822\n",
      "817 loss: 0.05127822\n",
      "818 loss: 0.05127822\n",
      "819 loss: 0.05127822\n",
      "820 loss: 0.05127822\n",
      "821 loss: 0.05127822\n",
      "822 loss: 0.05127822\n",
      "823 loss: 0.05127822\n",
      "824 loss: 0.05127822\n",
      "825 loss: 0.05127822\n",
      "826 loss: 0.05127822\n",
      "827 loss: 0.05127822\n",
      "828 loss: 0.05127822\n",
      "829 loss: 0.05127822\n",
      "830 loss: 0.05127822\n",
      "831 loss: 0.05127822\n",
      "832 loss: 0.05127822\n",
      "833 loss: 0.05127822\n",
      "834 loss: 0.05127822\n",
      "835 loss: 0.05127822\n",
      "836 loss: 0.05127822\n",
      "837 loss: 0.05127822\n",
      "838 loss: 0.05127822\n",
      "839 loss: 0.05127822\n",
      "840 loss: 0.05127822\n",
      "841 loss: 0.05127822\n",
      "842 loss: 0.05127822\n",
      "843 loss: 0.05127822\n",
      "844 loss: 0.05127822\n",
      "845 loss: 0.05127822\n",
      "846 loss: 0.05127822\n",
      "847 loss: 0.05127822\n",
      "848 loss: 0.05127822\n",
      "849 loss: 0.05127822\n",
      "850 loss: 0.05127822\n",
      "851 loss: 0.05127822\n",
      "852 loss: 0.05127822\n",
      "853 loss: 0.05127822\n",
      "854 loss: 0.05127822\n",
      "855 loss: 0.05127822\n",
      "856 loss: 0.05127822\n",
      "857 loss: 0.05127822\n",
      "858 loss: 0.05127822\n",
      "859 loss: 0.05127822\n",
      "860 loss: 0.05127822\n",
      "861 loss: 0.05127822\n",
      "862 loss: 0.05127822\n",
      "863 loss: 0.05127822\n",
      "864 loss: 0.05127822\n",
      "865 loss: 0.05127822\n",
      "866 loss: 0.05127822\n",
      "867 loss: 0.05127822\n",
      "868 loss: 0.05127822\n",
      "869 loss: 0.05127822\n",
      "870 loss: 0.05127822\n",
      "871 loss: 0.05127822\n",
      "872 loss: 0.05127822\n",
      "873 loss: 0.05127822\n",
      "874 loss: 0.05127822\n",
      "875 loss: 0.05127822\n",
      "876 loss: 0.05127822\n",
      "877 loss: 0.05127822\n",
      "878 loss: 0.05127822\n",
      "879 loss: 0.05127822\n",
      "880 loss: 0.05127822\n",
      "881 loss: 0.05127822\n",
      "882 loss: 0.05127822\n",
      "883 loss: 0.05127822\n",
      "884 loss: 0.05127822\n",
      "885 loss: 0.05127822\n",
      "886 loss: 0.05127822\n",
      "887 loss: 0.05127822\n",
      "888 loss: 0.05127822\n",
      "889 loss: 0.05127822\n",
      "890 loss: 0.05127822\n",
      "891 loss: 0.05127822\n",
      "892 loss: 0.05127822\n",
      "893 loss: 0.05127822\n",
      "894 loss: 0.05127822\n",
      "895 loss: 0.05127822\n",
      "896 loss: 0.05127822\n",
      "897 loss: 0.05127822\n",
      "898 loss: 0.05127822\n",
      "899 loss: 0.05127822\n",
      "900 loss: 0.05127822\n",
      "901 loss: 0.05127822\n",
      "902 loss: 0.05127822\n",
      "903 loss: 0.05127822\n",
      "904 loss: 0.05127822\n",
      "905 loss: 0.05127822\n",
      "906 loss: 0.05127822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "907 loss: 0.05127822\n",
      "908 loss: 0.05127822\n",
      "909 loss: 0.05127822\n",
      "910 loss: 0.05127822\n",
      "911 loss: 0.05127822\n",
      "912 loss: 0.05127822\n",
      "913 loss: 0.05127822\n",
      "914 loss: 0.05127822\n",
      "915 loss: 0.05127822\n",
      "916 loss: 0.05127822\n",
      "917 loss: 0.05127822\n",
      "918 loss: 0.05127822\n",
      "919 loss: 0.05127822\n",
      "920 loss: 0.05127822\n",
      "921 loss: 0.05127822\n",
      "922 loss: 0.05127822\n",
      "923 loss: 0.05127822\n",
      "924 loss: 0.05127822\n",
      "925 loss: 0.05127822\n",
      "926 loss: 0.05127822\n",
      "927 loss: 0.05127822\n",
      "928 loss: 0.05127822\n",
      "929 loss: 0.05127822\n",
      "930 loss: 0.05127822\n",
      "931 loss: 0.05127822\n",
      "932 loss: 0.05127822\n",
      "933 loss: 0.05127822\n",
      "934 loss: 0.05127822\n",
      "935 loss: 0.05127822\n",
      "936 loss: 0.05127822\n",
      "937 loss: 0.05127822\n",
      "938 loss: 0.05127822\n",
      "939 loss: 0.05127822\n",
      "940 loss: 0.05127822\n",
      "941 loss: 0.05127822\n",
      "942 loss: 0.05127822\n",
      "943 loss: 0.05127822\n",
      "944 loss: 0.05127822\n",
      "945 loss: 0.05127822\n",
      "946 loss: 0.05127822\n",
      "947 loss: 0.05127822\n",
      "948 loss: 0.05127822\n",
      "949 loss: 0.05127822\n",
      "950 loss: 0.05127822\n",
      "951 loss: 0.05127822\n",
      "952 loss: 0.05127822\n",
      "953 loss: 0.05127822\n",
      "954 loss: 0.05127822\n",
      "955 loss: 0.05127822\n",
      "956 loss: 0.05127822\n",
      "957 loss: 0.05127822\n",
      "958 loss: 0.05127822\n",
      "959 loss: 0.05127822\n",
      "960 loss: 0.05127822\n",
      "961 loss: 0.05127822\n",
      "962 loss: 0.05127822\n",
      "963 loss: 0.05127822\n",
      "964 loss: 0.05127822\n",
      "965 loss: 0.05127822\n",
      "966 loss: 0.05127822\n",
      "967 loss: 0.05127822\n",
      "968 loss: 0.05127822\n",
      "969 loss: 0.05127822\n",
      "970 loss: 0.05127822\n",
      "971 loss: 0.05127822\n",
      "972 loss: 0.05127822\n",
      "973 loss: 0.05127822\n",
      "974 loss: 0.05127822\n",
      "975 loss: 0.05127822\n",
      "976 loss: 0.05127822\n",
      "977 loss: 0.05127822\n",
      "978 loss: 0.05127822\n",
      "979 loss: 0.05127822\n",
      "980 loss: 0.05127822\n",
      "981 loss: 0.05127822\n",
      "982 loss: 0.05127822\n",
      "983 loss: 0.05127822\n",
      "984 loss: 0.05127822\n",
      "985 loss: 0.05127822\n",
      "986 loss: 0.05127822\n",
      "987 loss: 0.05127822\n",
      "988 loss: 0.05127822\n",
      "989 loss: 0.05127822\n",
      "990 loss: 0.05127822\n",
      "991 loss: 0.05127822\n",
      "992 loss: 0.05127822\n",
      "993 loss: 0.05127822\n",
      "994 loss: 0.05127822\n",
      "995 loss: 0.05127822\n",
      "996 loss: 0.05127822\n",
      "997 loss: 0.05127822\n",
      "998 loss: 0.05127822\n",
      "999 loss: 0.05127822\n",
      "Predicting\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def run():\n",
    "  x_batch, y_batch = generate_dataset()\n",
    "  x, y, y_pred, loss = linear_regression()\n",
    "\n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.1)\n",
    "  train_op = optimizer.minimize(loss)\n",
    "\n",
    "  with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    feed_dict = {x: x_batch, y: y_batch}\n",
    "\t\t\n",
    "    for i in range(1000):\n",
    "      session.run(train_op, feed_dict)\n",
    "      print(i, \"loss:\", loss.eval(feed_dict))\n",
    "\n",
    "    print('Predicting')\n",
    "    y_pred_batch = session.run(y_pred, {x : x_batch})\n",
    "\n",
    "  plt.scatter(x_batch, y_batch)\n",
    "  plt.plot(x_batch, y_pred_batch, color='red')\n",
    "  plt.xlim(0, 2)\n",
    "  plt.ylim(0, 2)\n",
    "  plt.show()\n",
    "  plt.savefig('plot.png')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
